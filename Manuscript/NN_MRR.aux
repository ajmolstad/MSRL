\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{apalike}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{belloni2011square}
\citation{turlach2005simultaneous,yuan2007dimension,obozinski2011support}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\newlabel{eq:MVR}{{1}{2}{Introduction}{equation.1.1}{}}
\citation{rothman2010sparse,yin2011sparse}
\citation{wang2015joint}
\citation{rothman2010sparse}
\citation{yin2011sparse}
\newlabel{eq:MSRL}{{2}{3}{Introduction}{equation.1.2}{}}
\citation{van2016chi2}
\citation{van2016estimation}
\citation{van2016chi2}
\citation{van2016chi2}
\citation{stucky2017asymptotic}
\citation{cvx}
\citation{van2016chi2}
\citation{van2016estimation}
\citation{belloni2011square}
\citation{belloni2011square}
\@writefile{toc}{\contentsline {section}{\numberline {2}The multivariate square-root lasso}{5}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Review of the univariate square-root lasso}{5}{subsection.2.1}}
\citation{bickel2009simultaneous}
\citation{bickel2009simultaneous}
\citation{belloni2011square}
\citation{belloni2011square}
\citation{sun2012scaled}
\newlabel{eq:lassoTP}{{3}{6}{Review of the univariate square-root lasso}{equation.2.3}{}}
\newlabel{eq:uni_sqrtlasso}{{4}{6}{Review of the univariate square-root lasso}{equation.2.4}{}}
\citation{belloni2011square}
\citation{liu2015calibrated}
\citation{liu2015calibrated}
\citation{liu2015calibrated}
\newlabel{eq:sqrtlassoTP}{{5}{7}{Review of the univariate square-root lasso}{equation.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Implicit covariance estimation}{7}{subsection.2.2}}
\citation{van2016estimation}
\newlabel{eq:joint_interp}{{6}{8}{Implicit covariance estimation}{equation.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Statistical properties of the multivariate square-root lasso}{8}{subsection.2.3}}
\citation{eaton}
\newlabel{thm:asymp}{{1}{10}{Statistical properties of the multivariate square-root lasso}{theorem.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Computation}{11}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Properties of the solution}{11}{subsection.3.1}}
\citation{parikh2014proximal}
\citation{parikh2014proximal}
\newlabel{eq:first_order}{{7}{12}{Properties of the solution}{equation.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Prox-linear ADMM}{12}{subsection.3.2}}
\citation{boyd2011distributed}
\citation{deng2016global}
\newlabel{eq:constrained}{{8}{13}{Prox-linear ADMM}{equation.3.8}{}}
\newlabel{eq:phi_update}{{9}{13}{Prox-linear ADMM}{equation.3.9}{}}
\newlabel{eq:beta_update}{{10}{13}{Prox-linear ADMM}{equation.3.10}{}}
\citation{lange2016mm}
\newlabel{eq:penalized_reg}{{12}{14}{Prox-linear ADMM}{equation.3.12}{}}
\newlabel{eq:prox_beta}{{13}{14}{Prox-linear ADMM}{equation.3.13}{}}
\citation{gu2018admm}
\citation{deng2016global}
\citation{deng2016global}
\citation{deng2016global}
\citation{boyd2011distributed}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Prox-linear ADMM for \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:MSRL}\unskip \@@italiccorr )}}\relax }}{15}{algorithm.1}}
\newlabel{conv_prop}{{3.2}{15}{Prox-linear ADMM}{prop.2}{}}
\citation{watson1992characterization}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Fast first order algorithm for large $n$}{16}{subsection.3.3}}
\newlabel{eq:gradient_NN}{{14}{16}{Fast first order algorithm for large $n$}{equation.3.14}{}}
\newlabel{eq:majorization}{{15}{16}{Fast first order algorithm for large $n$}{equation.3.15}{}}
\newlabel{eq:prox_updateI}{{16}{16}{Fast first order algorithm for large $n$}{equation.3.16}{}}
\citation{li2016fast}
\citation{parikh2014proximal}
\citation{beck2009fast}
\citation{van2016chi2}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Computational complexity and tuning parameter selection}{17}{subsection.3.4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Monotone accelerated proximal gradient descent for \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:MSRL}\unskip \@@italiccorr )}}\relax }}{18}{algorithm.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Simulation studies}{19}{section.4}}
\newlabel{sec:sim_studies}{{4}{19}{Simulation studies}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data generating models}{19}{subsection.4.1}}
\citation{liu2015calibrated}
\citation{liu2015calibrated}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Competing methods}{20}{subsection.4.2}}
\newlabel{subsec:comp_methods}{{4.2}{20}{Competing methods}{subsection.4.2}{}}
\citation{belloni2011square}
\citation{rothman2010sparse}
\newlabel{eq:lasso_q}{{17}{21}{Competing methods}{equation.4.17}{}}
\citation{rothman2010sparse}
\citation{yuan2007dimension}
\citation{molstad2016indirect}
\citation{liu2015calibrated}
\citation{rothman2010sparse}
\newlabel{eq:MRCE}{{18}{22}{Competing methods}{equation.4.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Results}{22}{subsection.4.3}}
\newlabel{subsec:Results}{{4.3}{22}{Results}{subsection.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Average log-model error over one hundred independent replications under Model 1 -- 4 with $\xi $ or $(\rm  cond)$ varying and $q=50$.\relax }}{23}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:rho_Results}{{1}{23}{Average log-model error over one hundred independent replications under Model 1 -- 4 with $\xi $ or $(\rm cond)$ varying and $q=50$.\relax }{figure.caption.1}{}}
\citation{eaton}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average true positive and false positive (times 100) rates for identifying nonzero entries in $\beta _*$. \relax }}{24}{table.caption.2}}
\newlabel{table:TPRFNR}{{1}{24}{Average true positive and false positive (times 100) rates for identifying nonzero entries in $\beta _*$. \relax }{table.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Theoretical tuning results}{24}{subsection.4.4}}
\newlabel{subsec:TP_sel}{{4.4}{24}{Theoretical tuning results}{subsection.4.4}{}}
\citation{belloni2011square}
\citation{belloni2011square}
\citation{belloni2011square}
\citation{belloni2011square}
\citation{weinstein2013cancer}
\citation{wang2015joint}
\citation{lee2012simultaneous}
\citation{wang2015joint}
\citation{lee2012simultaneous}
\citation{wan2015tcga2stat}
\citation{wang2015joint}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Average log-model error over one hundred independent replications under Model 1 - 2 with $\xi $ varying.\relax }}{26}{figure.caption.3}}
\newlabel{fig:TP_Results}{{2}{26}{Average log-model error over one hundred independent replications under Model 1 - 2 with $\xi $ varying.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Glimoblastoma multiforme application}{26}{section.5}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Weighted prediction error and nuclear norm prediction error averaged over 100 training/testing splits for the five considered methods. \relax }}{27}{table.caption.4}}
\newlabel{table:TCGA}{{2}{27}{Weighted prediction error and nuclear norm prediction error averaged over 100 training/testing splits for the five considered methods. \relax }{table.caption.4}{}}
\citation{WANG2013135}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{28}{section.6}}
\citation{rothman2010sparse}
\citation{yin2011sparse}
\bibdata{NN_MRR}
\bibcite{beck2009fast}{{1}{2009}{{Beck and Teboulle}}{{}}}
\bibcite{belloni2011square}{{2}{2011}{{Belloni et~al.}}{{}}}
\bibcite{bickel2009simultaneous}{{3}{2009}{{Bickel et~al.}}{{}}}
\bibcite{boyd2011distributed}{{4}{2011}{{Boyd et~al.}}{{}}}
\bibcite{deng2016global}{{5}{2016}{{Deng and Yin}}{{}}}
\bibcite{eaton}{{6}{1989}{{Eaton}}{{}}}
\bibcite{cvx}{{7}{2014}{{Grant and Boyd}}{{}}}
\bibcite{gu2018admm}{{8}{2018}{{Gu et~al.}}{{}}}
\bibcite{lange2016mm}{{9}{2016}{{Lange}}{{}}}
\bibcite{laurent2000adaptive}{{10}{2000}{{Laurent and Massart}}{{}}}
\bibcite{lee2012simultaneous}{{11}{2012}{{Lee and Liu}}{{}}}
\bibcite{li2016fast}{{12}{2016}{{Li et~al.}}{{}}}
\bibcite{liu2015calibrated}{{13}{2015}{{Liu et~al.}}{{}}}
\bibcite{molstad2016indirect}{{14}{2016}{{Molstad and Rothman}}{{}}}
\bibcite{negahban2012unified}{{15}{2012}{{Negahban et~al.}}{{}}}
\bibcite{obozinski2011support}{{16}{2011}{{Obozinski et~al.}}{{}}}
\bibcite{parikh2014proximal}{{17}{2014}{{Parikh and Boyd}}{{}}}
\bibcite{rothman2008sparse}{{18}{2008}{{Rothman et~al.}}{{}}}
\bibcite{rothman2010sparse}{{19}{2010}{{Rothman et~al.}}{{}}}
\bibcite{stucky2017asymptotic}{{20}{2017}{{Stucky}}{{}}}
\bibcite{sun2012scaled}{{21}{2012}{{Sun and Zhang}}{{}}}
\bibcite{turlach2005simultaneous}{{22}{2005}{{Turlach et~al.}}{{}}}
\bibcite{van2016estimation}{{23}{2016}{{Van~de Geer}}{{}}}
\bibcite{van2016chi2}{{24}{2016}{{Van~de Geer and Stucky}}{{}}}
\bibcite{wan2015tcga2stat}{{25}{2015}{{Wan et~al.}}{{}}}
\bibcite{wang2015joint}{{26}{2015}{{Wang}}{{}}}
\bibcite{WANG2013135}{{27}{2013}{{Wang}}{{}}}
\bibcite{watson1992characterization}{{28}{1992}{{Watson}}{{}}}
\bibcite{weinstein2013cancer}{{29}{2013}{{Weinstein et~al.}}{{}}}
\bibcite{witten2009covariance}{{30}{2009}{{Witten and Tibshirani}}{{}}}
\bibcite{yin2011sparse}{{31}{2011}{{Yin and Li}}{{}}}
\bibcite{yuan2007dimension}{{32}{2007}{{Yuan et~al.}}{{}}}
\citation{eaton}
\citation{eaton}
\@writefile{toc}{\contentsline {section}{\numberline {1}Proofs of Proposition 1 and Theorem 1}{1}{section.1}}
\newlabel{lemma:eaton}{{1}{1}{Proofs of Proposition 1 and Theorem 1}{lemma.1}{}}
\citation{watson1992characterization}
\newlabel{lemma:grad}{{2}{2}{Proofs of Proposition 1 and Theorem 1}{lemma.2}{}}
\newlabel{eq:partial1}{{19}{2}{Proofs of Proposition 1 and Theorem 1}{equation.1.19}{}}
\newlabel{eq:partial2}{{20}{2}{Proofs of Proposition 1 and Theorem 1}{equation.1.20}{}}
\newlabel{RSClemma}{{3}{3}{Proofs of Proposition 1 and Theorem 1}{lemma.3}{}}
\citation{negahban2012unified}
\citation{rothman2008sparse}
\citation{rothman2008sparse}
\newlabel{A3_cond}{{21}{4}{Proofs of Proposition 1 and Theorem 1}{equation.1.21}{}}
\newlabel{lemma:cone}{{4}{4}{Proofs of Proposition 1 and Theorem 1}{lemma.4}{}}
\citation{rothman2008sparse}
\citation{negahban2012unified}
\newlabel{main_lemma}{{5}{5}{Proofs of Proposition 1 and Theorem 1}{lemma.5}{}}
\citation{rothman2008sparse}
\citation{rothman2008sparse}
\newlabel{holder}{{22}{6}{Proofs of Proposition 1 and Theorem 1}{equation.1.22}{}}
\newlabel{lemmaFreeLunch}{{6}{6}{Proofs of Proposition 1 and Theorem 1}{lemma.6}{}}
\citation{van2016estimation}
\citation{laurent2000adaptive}
\newlabel{lemmaConc}{{7}{8}{Proofs of Proposition 1 and Theorem 1}{lemma.7}{}}
\newlabel{eq:unionbound}{{24}{8}{Proofs of Proposition 1 and Theorem 1}{equation.1.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Additional simulation results}{9}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Weighted prediction error results}{9}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Average weighted prediction error over one hundred independent replications under Model 1 - 4 with $\xi $ or $(\rm  cond)$ varying and $q=50$.\relax }}{10}{figure.caption.6}}
\newlabel{fig:predErr_Results}{{3}{10}{Average weighted prediction error over one hundred independent replications under Model 1 - 4 with $\xi $ or $(\rm cond)$ varying and $q=50$.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Model 1 and 2 with $q$ varying}{10}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces (a) Model error and (c) weighted prediction error averaged over one hundred independent replications under Model 1 with $q$ varying and $\xi = 0.9$. (b) Model error and (d) weighted prediction error averaged over one hundred independent replications under Model 2 with $q$ varying and $\xi = 0.9$.\relax }}{11}{figure.caption.7}}
\newlabel{fig:q_Results}{{4}{11}{(a) Model error and (c) weighted prediction error averaged over one hundred independent replications under Model 1 with $q$ varying and $\xi = 0.9$. (b) Model error and (d) weighted prediction error averaged over one hundred independent replications under Model 2 with $q$ varying and $\xi = 0.9$.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Computational details}{12}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Derivation of proximal ADMM $\beta $ update}{12}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Stochastic approximation of the gradient}{13}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Method for refitting with unstructured covariance}{13}{subsection.3.3}}
\newlabel{eq:SUR}{{25}{13}{Method for refitting with unstructured covariance}{equation.3.25}{}}
\citation{witten2009covariance}
